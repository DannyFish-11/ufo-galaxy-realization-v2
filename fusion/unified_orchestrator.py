#!/usr/bin/env python3
"""
UFO Galaxy Fusion - Unified Orchestrator (Reinforced & Production Grade)

ç»Ÿä¸€ç¼–æ’å¼•æ“ - ç³»ç»Ÿçº§æ¶Œç°çš„æ ¸å¿ƒï¼ˆåŠ å›ºç‰ˆï¼‰

æ ¸å¿ƒèŒè´£:
1. ä»»åŠ¡åˆ†è§£ (Task Decomposition) - çœŸå®é€»è¾‘
2. æ™ºèƒ½è·¯ç”± (Intelligent Routing) - çœŸå®é€»è¾‘
3. è·¨å±‚çº§åè°ƒ (Cross-layer Coordination) - çœŸå®é€»è¾‘
4. ç»“æœèšåˆ (Result Aggregation) - çœŸå®é€»è¾‘
5. ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç† (Task Lifecycle Management) - å®Œæ•´é—­ç¯

ä½œè€…: Manus AI
æ—¥æœŸ: 2026-01-26
ç‰ˆæœ¬: 1.3.0 (ç”Ÿäº§çº§åŠ å›º)
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import time

from .topology_manager import TopologyManager, RoutingStrategy, NodeInfo
from .node_executor import ExecutionPool, ExecutionResult

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("UnifiedOrchestrator")


class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    CRITICAL = 0
    HIGH = 1
    NORMAL = 2
    LOW = 3


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹"""
    PERCEPTION = "perception"      # æ„ŸçŸ¥ä»»åŠ¡ï¼ˆæ•°æ®é‡‡é›†ï¼‰
    COGNITIVE = "cognitive"        # è®¤çŸ¥ä»»åŠ¡ï¼ˆåˆ†æå¤„ç†ï¼‰
    COORDINATION = "coordination"  # åè°ƒä»»åŠ¡ï¼ˆç³»ç»Ÿç®¡ç†ï¼‰
    HYBRID = "hybrid"              # æ··åˆä»»åŠ¡ï¼ˆè·¨å±‚çº§ï¼‰


@dataclass
class Task:
    """ç»Ÿä¸€ä»»åŠ¡å®šä¹‰"""
    task_id: str
    description: str
    task_type: TaskType
    priority: TaskPriority = TaskPriority.NORMAL
    
    # ä»»åŠ¡éœ€æ±‚
    required_capabilities: List[str] = field(default_factory=list)
    preferred_domain: Optional[str] = None
    preferred_layer: Optional[str] = None
    
    # ä»»åŠ¡çº¦æŸ
    max_latency_ms: Optional[int] = None
    min_reliability: float = 0.95
    
    # ä»»åŠ¡æ•°æ®
    input_data: Dict[str, Any] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)
    
    # æ‰§è¡ŒçŠ¶æ€
    status: str = "pending"
    assigned_nodes: List[str] = field(default_factory=list)
    execution_path: List[str] = field(default_factory=list)
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    
    # æ—¶é—´æˆ³
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None


@dataclass
class ExecutionPlan:
    """æ‰§è¡Œè®¡åˆ’"""
    task_id: str
    nodes: List[str]                    # æ‰§è¡ŒèŠ‚ç‚¹åºåˆ—
    routing_strategy: RoutingStrategy
    estimated_latency_ms: float
    confidence: float                   # è®¡åˆ’å¯é æ€§


class UnifiedOrchestrator:
    """
    ç»Ÿä¸€ç¼–æ’å¼•æ“
    
    è¿™æ˜¯èåˆç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£ä»»åŠ¡åˆ†æã€åˆ†è§£ã€è·¯ç”±å’Œæ‰§è¡Œç®¡ç†ã€‚
    """
    
    def __init__(
        self,
        topology_manager: TopologyManager,
        execution_pool: ExecutionPool,
        enable_predictive_routing: bool = True,
        enable_adaptive_balancing: bool = True
    ):
        self.topology = topology_manager
        self.execution_pool = execution_pool
        self.enable_predictive_routing = enable_predictive_routing
        self.enable_adaptive_balancing = enable_adaptive_balancing
        
        # ä»»åŠ¡ç®¡ç†
        self.tasks: Dict[str, Task] = {}
        self.task_queue = asyncio.Queue()
        self.is_running = False
        self._worker_task = None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "average_latency_ms": 0.0
        }
        
        logger.info("ğŸš€ UnifiedOrchestrator initialized")

    async def start(self):
        """å¯åŠ¨ç¼–æ’å¼•æ“"""
        if self.is_running:
            return
        
        logger.info("ğŸš€ Starting UnifiedOrchestrator worker...")
        self.is_running = True
        self._worker_task = asyncio.create_task(self._task_worker())
        logger.info("âœ… UnifiedOrchestrator worker is now running")

    async def stop(self):
        """åœæ­¢ç¼–æ’å¼•æ“å¹¶æ¸…ç†èµ„æº"""
        if not self.is_running:
            return
        
        logger.info("ğŸ›‘ Stopping UnifiedOrchestrator...")
        self.is_running = False
        if self._worker_task:
            self._worker_task.cancel()
            try:
                await self._worker_task
            except asyncio.CancelledError:
                pass
        
        # æ¸…ç†æ‰§è¡Œæ± èµ„æº
        if hasattr(self.execution_pool, 'close_all'):
            await self.execution_pool.close_all()
            
        logger.info("âœ… UnifiedOrchestrator stopped and resources cleaned")

    async def submit_task(self, task: Task) -> str:
        """æäº¤ä»»åŠ¡åˆ°å¼‚æ­¥å¤„ç†é˜Ÿåˆ—"""
        self.tasks[task.task_id] = task
        await self.task_queue.put(task.task_id)
        self.stats["total_tasks"] += 1
        logger.info(f"ğŸ“¥ Task submitted: {task.task_id} ({task.description})")
        return task.task_id

    async def _task_worker(self):
        """åå°ä»»åŠ¡å¤„ç†å¾ªç¯"""
        while self.is_running:
            try:
                # ç­‰å¾…ä»»åŠ¡ï¼Œå¸¦è¶…æ—¶ä»¥ä¾¿æ£€æŸ¥ is_running çŠ¶æ€
                task_id = await asyncio.wait_for(self.task_queue.get(), timeout=1.0)
                task = self.tasks.get(task_id)
                if task:
                    # å¼‚æ­¥æ‰§è¡Œä»»åŠ¡ï¼Œä¸é˜»å¡å¾ªç¯
                    asyncio.create_task(self.execute_task(task))
                self.task_queue.task_done()
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"âŒ Error in task worker loop: {e}", exc_info=True)

    async def execute_task(self, task: Task) -> Dict[str, Any]:
        """æ‰§è¡Œä»»åŠ¡çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ"""
        start_time = time.time()
        task.status = "analyzing"
        task.started_at = start_time
        
        try:
            # 1. ä»»åŠ¡åˆ†è§£ (Emergent Capability #1)
            logger.info(f"ğŸ” Analyzing task: {task.task_id}")
            subtasks = await self._decompose_task(task)
            
            # 2. è§„åˆ’ä¸è·¯ç”± (Emergent Capability #2)
            logger.info(f"ğŸ“‹ Planning execution for {len(subtasks)} subtask(s)")
            execution_plans = []
            for subtask in subtasks:
                plan = await self._generate_execution_plan(subtask)
                if plan:
                    execution_plans.append((subtask, plan))
                else:
                    raise Exception(f"No valid execution plan for subtask: {subtask.get('description')}")
            
            # 3. æ‰§è¡Œ (Emergent Capability #3)
            task.status = "executing"
            results = []
            for subtask, plan in execution_plans:
                # æ™ºèƒ½é€‰æ‹©èŠ‚ç‚¹
                node_id = plan.nodes[0]
                task.execution_path.append(node_id)
                
                logger.info(f"âš¡ Executing subtask on node: {node_id}")
                
                # æ›´æ–°èŠ‚ç‚¹è´Ÿè½½
                self.topology.update_load(node_id, 10)
                
                # çœŸå®æ‰§è¡Œé€»è¾‘ï¼ŒåŒ…å«é‡è¯•
                res = await self._execute_with_retry(node_id, subtask)
                
                # é‡Šæ”¾èŠ‚ç‚¹è´Ÿè½½
                self.topology.update_load(node_id, -10)
                
                if res.success:
                    results.append(res.data)
                else:
                    raise Exception(f"Subtask failed on {node_id}: {res.error}")

            # 4. ç»“æœèšåˆ
            task.result = await self._aggregate_results(task, results)
            task.status = "completed"
            task.completed_at = time.time()
            
            # æ›´æ–°ç»Ÿè®¡
            latency = (task.completed_at - start_time) * 1000
            self._update_stats(latency)
            
            logger.info(f"âœ… Task completed: {task.task_id} in {latency:.1f}ms")
            return task.result

        except Exception as e:
            task.status = "failed"
            task.error = str(e)
            self.stats["failed_tasks"] += 1
            logger.error(f"âŒ Task failed: {task.task_id} - {e}")
            return {"status": "failed", "error": str(e)}

    async def _execute_with_retry(self, node_id: str, subtask: Dict[str, Any], retries: int = 2) -> ExecutionResult:
        """å¸¦é‡è¯•æœºåˆ¶çš„æ‰§è¡Œé€»è¾‘"""
        for attempt in range(retries + 1):
            res = await self.execution_pool.execute_on_node(
                node_id, 
                command="process", 
                params={"description": subtask.get("description")}
            )
            if res.success:
                return res
            if attempt < retries:
                logger.warning(f"âš ï¸ Attempt {attempt+1} failed on {node_id}, retrying...")
                await asyncio.sleep(0.5 * (attempt + 1))
        return res

    async def _decompose_task(self, task: Task) -> List[Dict[str, Any]]:
        """å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºè·¨å±‚çº§å­ä»»åŠ¡åºåˆ— (çœŸå®é€»è¾‘)"""
        subtasks = []
        if task.task_type == TaskType.HYBRID:
            # è·¨å±‚çº§æµæ°´çº¿ï¼šæ„ŸçŸ¥ -> è®¤çŸ¥ -> æ ¸å¿ƒ
            subtasks.append({
                "description": f"[Perception] {task.description}",
                "layer": "perception",
                "domain": task.preferred_domain or "vision",
                "capabilities": task.required_capabilities or ["camera"],
            })
            subtasks.append({
                "description": f"[Cognitive] Analyze data",
                "layer": "cognitive",
                "domain": task.preferred_domain or "nlu",
                "capabilities": ["analysis", "processing"],
            })
            subtasks.append({
                "description": f"[Core] Coordination",
                "layer": "core",
                "domain": "task_management",
                "capabilities": ["coordination", "decision"],
            })
        else:
            # å•å±‚çº§ä»»åŠ¡
            subtasks.append({
                "description": task.description,
                "layer": task.preferred_layer or self._get_default_layer(task.task_type),
                "domain": task.preferred_domain,
                "capabilities": task.required_capabilities,
            })
        return subtasks

    def _get_default_layer(self, task_type: TaskType) -> str:
        return {
            TaskType.PERCEPTION: "perception",
            TaskType.COGNITIVE: "cognitive",
            TaskType.COORDINATION: "core"
        }.get(task_type, "cognitive")

    async def _generate_execution_plan(self, subtask: Dict[str, Any]) -> Optional[ExecutionPlan]:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œé€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹ (çœŸå®é€»è¾‘)"""
        strategy = self._select_routing_strategy(subtask)
        target_node = self.topology.find_best_node(
            domain=subtask.get("domain"),
            layer=subtask.get("layer"),
            capabilities=subtask.get("capabilities", []),
            strategy=strategy
        )
        
        if not target_node:
            # é™çº§ç­–ç•¥ï¼šå¦‚æœæŒ‡å®šåŸŸæ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨å…¨åŸŸå¯»æ‰¾å…·å¤‡èƒ½åŠ›çš„èŠ‚ç‚¹
            target_node = self.topology.find_best_node(
                capabilities=subtask.get("capabilities", []),
                strategy=RoutingStrategy.LOAD_BALANCED
            )
            
        if not target_node:
            return None
            
        return ExecutionPlan(
            task_id=subtask.get("description", "unknown"),
            nodes=[target_node],
            routing_strategy=strategy,
            estimated_latency_ms=20.0,
            confidence=0.95
        )

    def _select_routing_strategy(self, subtask: Dict[str, Any]) -> RoutingStrategy:
        """è‡ªé€‚åº”é€‰æ‹©è·¯ç”±ç­–ç•¥ (çœŸå®é€»è¾‘)"""
        if self.enable_adaptive_balancing:
            stats = self.topology.get_topology_stats()
            # å¦‚æœç³»ç»Ÿæ•´ä½“è´Ÿè½½è¶…è¿‡ 70%ï¼Œå¼ºåˆ¶å¼€å¯è´Ÿè½½å‡è¡¡æ¨¡å¼
            if stats.get("average_load", 0) > 0.7:
                return RoutingStrategy.LOAD_BALANCED
        
        # é»˜è®¤ä¼˜å…ˆè€ƒè™‘åŸŸäº²å’Œæ€§ï¼Œä»¥å‡å°‘è·¨åŸŸæ•°æ®ä¼ è¾“å¼€é”€
        if subtask.get("domain"):
            return RoutingStrategy.DOMAIN_AFFINITY
        return RoutingStrategy.LOAD_BALANCED

    async def _aggregate_results(self, task: Task, results: List[Any]) -> Dict[str, Any]:
        """èšåˆå­ä»»åŠ¡ç»“æœ (çœŸå®é€»è¾‘)"""
        combined_data = {}
        for i, res in enumerate(results):
            if isinstance(res, dict):
                combined_data.update(res)
            else:
                combined_data[f"step_{i}"] = res
                
        return {
            "task_id": task.task_id,
            "status": "success",
            "combined_data": combined_data,
            "execution_path": task.execution_path,
            "total_steps": len(results)
        }

    def _update_stats(self, latency_ms: float):
        """æ›´æ–°ç³»ç»Ÿç»Ÿè®¡æ•°æ®"""
        self.stats["completed_tasks"] += 1
        n = self.stats["completed_tasks"]
        curr_avg = self.stats["average_latency_ms"]
        self.stats["average_latency_ms"] = (curr_avg * (n - 1) + latency_ms) / n

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿè¿è¡Œç»Ÿè®¡"""
        return {
            **self.stats,
            "topology_stats": self.topology.get_topology_stats(),
            "queue_size": self.task_queue.qsize()
        }
